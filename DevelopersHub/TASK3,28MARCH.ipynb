{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4f26a1-6394-409a-b5c7-09c5bd876fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.1-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.6.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\delli\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl (443 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading pyarrow-19.0.1-cp311-cp311-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/25.3 MB 3.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.8/25.3 MB 4.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.1/25.3 MB 3.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.6/25.3 MB 4.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 3.1/25.3 MB 3.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.2/25.3 MB 3.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.2/25.3 MB 3.5 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 4.7/25.3 MB 3.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 5.2/25.3 MB 3.0 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 5.8/25.3 MB 2.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.0/25.3 MB 2.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 6.3/25.3 MB 2.5 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 6.6/25.3 MB 2.5 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 2.4 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 7.1/25.3 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 7.6/25.3 MB 2.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 7.9/25.3 MB 2.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 8.1/25.3 MB 2.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 8.4/25.3 MB 2.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 8.7/25.3 MB 2.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.2/25.3 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.4/25.3 MB 2.1 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.7/25.3 MB 2.1 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 10.0/25.3 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.2/25.3 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.5/25.3 MB 2.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 10.7/25.3 MB 2.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 11.5/25.3 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 11.8/25.3 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 12.1/25.3 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 12.1/25.3 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 12.3/25.3 MB 1.8 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 12.6/25.3 MB 1.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 12.8/25.3 MB 1.8 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 13.4/25.3 MB 1.8 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 13.6/25.3 MB 1.8 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 13.9/25.3 MB 1.8 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 14.2/25.3 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 14.7/25.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.9/25.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 15.2/25.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 15.7/25.3 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 16.0/25.3 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 16.5/25.3 MB 1.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.8/25.3 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 17.3/25.3 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 17.6/25.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 17.8/25.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 18.4/25.3 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.6/25.3 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 19.1/25.3 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 19.7/25.3 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 19.9/25.3 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.4/25.3 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.7/25.3 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 21.0/25.3 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 21.2/25.3 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 21.5/25.3 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 21.8/25.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.0/25.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.3/25.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.5/25.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.8/25.3 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.3/25.3 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.6/25.3 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.9/25.3 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.3 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.6/25.3 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.6.0-cp311-cp311-win_amd64.whl (120 kB)\n",
      "Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, filelock, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 datasets-3.5.0 dill-0.3.8 filelock-3.18.0 frozenlist-1.6.0 fsspec-2024.12.0 huggingface-hub-0.30.2 multidict-6.4.3 multiprocess-0.70.16 propcache-0.3.1 pyarrow-19.0.1 xxhash-3.5.0 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1686021a-8f9d-4185-8702-8d9320f6ab40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8a353920d84fa291acc170842a1bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delli\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\delli\\.cache\\huggingface\\hub\\datasets--cnn_dailymail. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86255b3865e47028a4c38100cf915f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843ea049ba5c4c1d9dced577c2ab125e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95da146be8cc4a8e8d73fe7952ece5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807ccbb64df849c5bfe46ba1d1feadc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd954666609f430aae8f631487aa425d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a43aa293f5433793ea82a8bf8114e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472d5e8522be40aebb26791a7ad06fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c276f4add0149d3a5d9598432d07478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803764b-1d82-4b12-b0f5-5410b7373355",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f020dbe-5465-40a8-aad9-f9c8be43ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea1607-8011-472d-ad24-033c3c8a2b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset = dataset.map(lambda x: {'article': preprocess(x['article']), 'highlights': preprocess(x['highlights'])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f33451-f1bc-4fe1-95aa-73edfde9d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extractive_summary(text, num_sentences=3):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return ' '.join(sentences[:num_sentences])\n",
    "\n",
    "# Example usage\n",
    "sample_article = dataset['train'][0]['article']\n",
    "print(extractive_summary(sample_article))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a830859-244d-452e-9539-31e2650f177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    inputs = tokenizer(example[\"article\"], max_length=1024, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(example[\"highlights\"], max_length=128, truncation=True)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"].shuffle().select(range(1000)),  # Subset for quick training\n",
    "    eval_dataset=tokenized_dataset[\"validation\"].shuffle().select(range(100)),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649bd0a-186d-4dc3-b58e-c79112f67dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "# Generate summaries and compute ROUGE scores\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in dataset[\"test\"].select(range(100)):\n",
    "    summary = summarizer(example[\"article\"], max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
    "    predictions.append(summary)\n",
    "    references.append(example[\"highlights\"])\n",
    "\n",
    "# Compute ROUGE scores\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba475b3-90a3-4fb8-bb7c-0a9fd6201470",
   "metadata": {},
   "source": [
    "📝 Project Overview: Text Summarization with CNN/Daily Mail Dataset\n",
    "This project focuses on implementing both extractive and abstractive summarization techniques on the CNN/Daily Mail dataset. The key steps undertaken are:\n",
    "\n",
    "Data Loading: Utilized the datasets library to load the \"cnn_dailymail\" dataset (version 3.0.0).\n",
    "\n",
    "Preprocessing: Cleaned the articles and summaries by removing extra whitespace and formatting inconsistencies.\n",
    "\n",
    "Extractive Summarization: Applied spaCy's English model to extract the first few sentences from each article as a basic extractive summary.\n",
    "\n",
    "Abstractive Summarization: Employed Hugging Face's Transformers library with the pre-trained facebook/bart-large-cnn model to generate abstractive summaries.\n",
    "\n",
    "Model Fine-Tuning: Fine-tuned the BART model on a subset of the dataset to improve summarization quality.\n",
    "\n",
    "Evaluation: Assessed the performance of the summarization model using ROUGE metrics to compare the generated summaries against the reference summaries.\n",
    "\n",
    "Reporting: Documented the entire process and results within this Jupyter Notebook for reproducibility and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b9222-bb90-4c8e-9c72-8ceaf2505c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
