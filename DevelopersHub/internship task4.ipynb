{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90b416e-d5f1-48ea-bb19-c8f697bf3f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "0   0.446982  -2.153731  -0.638586   1.223856   0.239858  -0.592241   \n",
      "1  -0.230401  -0.758495  -0.924233   0.260281  -1.846188  -0.957151   \n",
      "2   0.281009  -1.315816  -2.132596   0.307613   3.243093   1.352203   \n",
      "3  -0.389924  -1.751829   0.158053   0.313184  -0.945746   0.455904   \n",
      "4  -1.571152   1.006730   1.081514  -0.350778  -0.070220   0.715493   \n",
      "\n",
      "   Feature_7  Feature_8  Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "0   0.486310   1.653310   0.337956    0.000756    0.623087    0.975713   \n",
      "1  -0.929511   0.890198  -0.963759   -0.048652    1.035249    0.343788   \n",
      "2   2.307916   1.012637  -0.524567    0.039447   -0.158154    0.424067   \n",
      "3   0.608246  -0.096624  -0.606503   -0.694600   -0.415967   -0.459090   \n",
      "4  -2.522278   0.037542  -0.227720   -1.520287    1.091805   -1.399078   \n",
      "\n",
      "   Feature_13       PRICE  \n",
      "0    0.685858  107.145884  \n",
      "1    0.032797 -105.290296  \n",
      "2   -1.435910 -107.635261  \n",
      "3   -1.154363 -403.216074  \n",
      "4    0.450963 -236.401341  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "#  synthetic regression dataset\n",
    "X, y = make_regression(n_samples=500, n_features=13, noise=10.0, random_state=42)\n",
    "\n",
    "#  DataFrame with 13 features like boston housing\n",
    "feature_names = [f'Feature_{i+1}' for i in range(13)]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Add the target column (house prices)\n",
    "df['PRICE'] = y\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b502c8c3-cf23-4efe-a0be-d077b31dfbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "0   0.442752  -2.066341  -0.525118   1.206881   0.274816  -0.598714   \n",
      "1  -0.245502  -0.700016  -0.800215   0.220096  -1.765479  -0.963312   \n",
      "2   0.274116  -1.245788  -1.963945   0.268568   3.212185   1.344068   \n",
      "3  -0.407586  -1.672767   0.242097   0.274274  -0.884786   0.448535   \n",
      "4  -1.607773   1.028633   1.131448  -0.405682  -0.028462   0.707902   \n",
      "\n",
      "   Feature_7  Feature_8  Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "0   0.550403   1.613891   0.309583   -0.061330    0.593682    1.046821   \n",
      "1  -0.902937   0.875005  -1.067124   -0.110160    1.008923    0.381229   \n",
      "2   2.420281   0.993557  -0.602630   -0.023092   -0.193395    0.465785   \n",
      "3   0.675570  -0.080491  -0.689286   -0.748545   -0.453134   -0.464424   \n",
      "4  -2.537912   0.049416  -0.288681   -1.564565    1.065902   -1.454492   \n",
      "\n",
      "   Feature_13  \n",
      "0    0.690171  \n",
      "1    0.039674  \n",
      "2   -1.423265  \n",
      "3   -1.142824  \n",
      "4    0.456198  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = df.drop('PRICE', axis=1)\n",
    "y = df['PRICE']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame for readability\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(X_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0444367-bb6f-4651-9294-e29d4c2b0c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: MSE = 41473.8717\n",
      "Epoch 100: MSE = 1204.4911\n",
      "Epoch 200: MSE = 146.4870\n",
      "Epoch 300: MSE = 110.7564\n",
      "Epoch 400: MSE = 109.3804\n",
      "Epoch 500: MSE = 109.3241\n",
      "Epoch 600: MSE = 109.3217\n",
      "Epoch 700: MSE = 109.3216\n",
      "Epoch 800: MSE = 109.3216\n",
      "Epoch 900: MSE = 109.3216\n",
      "\n",
      "Final Weights (Theta):\n",
      " [[ 4.60894130e+00]\n",
      " [ 9.57796055e+01]\n",
      " [ 9.50214375e+01]\n",
      " [ 1.20075366e+00]\n",
      " [ 3.28556056e+01]\n",
      " [ 5.62937713e-02]\n",
      " [ 2.21277684e+01]\n",
      " [-4.04290447e-01]\n",
      " [ 6.40174881e+01]\n",
      " [ 6.35028673e+01]\n",
      " [ 9.29062109e+01]\n",
      " [-3.69751607e-01]\n",
      " [ 5.61370946e+01]\n",
      " [ 7.99015708e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert DataFrames to numpy arrays\n",
    "X = X_scaled.values  # Features (500, 13)\n",
    "y = y.values.reshape(-1, 1)  # Target (500, 1)\n",
    "\n",
    "# Add a bias term (X0 = 1) for the intercept\n",
    "X = np.c_[np.ones((X.shape[0], 1)), X]  # Shape (500, 14)\n",
    "\n",
    "# Initialize weights randomly\n",
    "theta = np.random.randn(X.shape[1], 1)  # (14, 1)\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Gradient Descent\n",
    "for i in range(epochs):\n",
    "    # Predictions: X * theta\n",
    "    y_pred = np.dot(X, theta)\n",
    "    \n",
    "    # Compute error\n",
    "    error = y_pred - y\n",
    "    \n",
    "    # Compute gradient\n",
    "    gradients = (2 / X.shape[0]) * np.dot(X.T, error)\n",
    "    \n",
    "    # Update weights\n",
    "    theta -= learning_rate * gradients\n",
    "    \n",
    "    # Loss every 100 epochs\n",
    "    if i % 100 == 0:\n",
    "        mse = np.mean(error ** 2)\n",
    "        print(f'Epoch {i}: MSE = {mse:.4f}')\n",
    "\n",
    "# Final weights\n",
    "print(\"\\nFinal Weights (Theta):\\n\", theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d15ac85-0f3e-4b50-b343-e8ca7d68ce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š RMSE: 10.4557\n",
      "ðŸ“ˆ RÂ² Score: 0.9974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred = np.dot(X, theta)\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "# RÂ² Score\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f\"ðŸ“Š RMSE: {rmse:.4f}\")\n",
    "print(f\"ðŸ“ˆ RÂ² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91fbc99b-310b-4aca-b319-b82613ef3508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random Forest (Minimal) model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleRandomForest:\n",
    "    def __init__(self, n_trees=10, max_samples=0.8):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_samples = max_samples  # Fraction of data for bootstrap\n",
    "        self.trees = []\n",
    "\n",
    "    def bootstrap_sample(self, X, y):\n",
    "        # Randomly sample a fraction of the data with replacement\n",
    "        n_samples = int(X.shape[0] * self.max_samples)\n",
    "        indices = np.random.choice(X.shape[0], n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            # Create bootstrap sample\n",
    "            X_sample, y_sample = self.bootstrap_sample(X, y)\n",
    "            # Create a simple decision stump (one-level tree)\n",
    "            tree = self.decision_stump(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def decision_stump(self, X, y):\n",
    "        # Find the best feature and threshold to split on\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_mse = float('inf')\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feature] < threshold\n",
    "                right_mask = ~left_mask\n",
    "\n",
    "                # Split the data\n",
    "                if sum(left_mask) == 0 or sum(right_mask) == 0:\n",
    "                    continue  # Skip empty splits\n",
    "\n",
    "                # Calculate MSE for left and right splits\n",
    "                mse_left = np.mean((y[left_mask] - np.mean(y[left_mask])) ** 2)\n",
    "                mse_right = np.mean((y[right_mask] - np.mean(y[right_mask])) ** 2)\n",
    "                mse = (mse_left * sum(left_mask) + mse_right * sum(right_mask)) / len(y)\n",
    "\n",
    "                # Keep track of the best split\n",
    "                if mse < best_mse:\n",
    "                    best_feature, best_threshold, best_mse = feature, threshold, mse\n",
    "\n",
    "        return (best_feature, best_threshold)\n",
    "\n",
    "    def predict_single(self, x, tree):\n",
    "        # Predict based on a single decision stump\n",
    "        feature, threshold = tree\n",
    "        return 1 if x[feature] < threshold else 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Collect predictions from all trees\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            tree_preds = [self.predict_single(X[i], tree) for tree in self.trees]\n",
    "            # Average of predictions (majority voting)\n",
    "            predictions.append(np.mean(tree_preds))\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_model = SimpleRandomForest(n_trees=10)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X)\n",
    "\n",
    "print(\"âœ… Random Forest (Minimal) model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3b0822-5a51-42ac-9fec-edff03c825d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š RMSE (Random Forest): 206.1930\n",
      "ðŸ“ˆ RÂ² Score (Random Forest): -0.0019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Reshape predictions for compatibility if needed\n",
    "y_pred_rf = y_pred_rf.flatten()\n",
    "\n",
    "# RMSE\n",
    "rmse_rf = np.sqrt(mean_squared_error(y, y_pred_rf))\n",
    "\n",
    "# RÂ² Score\n",
    "r2_rf = r2_score(y, y_pred_rf)\n",
    "\n",
    "print(f\"ðŸ“Š RMSE (Random Forest): {rmse_rf:.4f}\")\n",
    "print(f\"ðŸ“ˆ RÂ² Score (Random Forest): {r2_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eebb417-3a1b-4859-8980-dd0f9d9b3b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ³ Random Forest - RMSE: 139.4406\n",
      "ðŸŒ³ Random Forest - RÂ² Score: 0.5418\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleRandomForest:\n",
    "    def __init__(self, n_estimators=10, max_features=5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        for _ in range(self.n_estimators):\n",
    "            # (Random Rows)\n",
    "            idx = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            # Random Feature Selection\n",
    "            features = np.random.choice(n_features, self.max_features, replace=False)\n",
    "            \n",
    "            # Fit a simple linear model on selected features\n",
    "            X_sample = X[idx][:, features]\n",
    "            y_sample = y[idx]\n",
    "            coef = np.linalg.pinv(X_sample) @ y_sample  # Linear regression\n",
    "            \n",
    "            # Store model and features\n",
    "            self.models.append((features, coef))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for features, coef in self.models:\n",
    "            # Get predictions for each tree\n",
    "            preds.append(X[:, features] @ coef)  # Fixed this line\n",
    "        return np.mean(preds, axis=0)  # Average predictions\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_model = SimpleRandomForest(n_estimators=10, max_features=5)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_rf))\n",
    "r2 = r2_score(y, y_pred_rf)\n",
    "\n",
    "print(f\"ðŸŒ³ Random Forest - RMSE: {rmse:.4f}\")\n",
    "print(f\"ðŸŒ³ Random Forest - RÂ² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce1daca7-d62e-4fa3-b8e1-d86e4b9629d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Linear Regression - RMSE: 10.4557\n",
      "ðŸ“ˆ Linear Regression - RÂ² Score: 0.9974\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'theta' is the final weights from Linear Regression\n",
    "y_pred_linear = X.dot(theta)\n",
    "\n",
    "# Evaluate Linear Regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse_linear = np.sqrt(mean_squared_error(y, y_pred_linear))\n",
    "r2_linear = r2_score(y, y_pred_linear)\n",
    "\n",
    "print(f\"ðŸ“ˆ Linear Regression - RMSE: {rmse_linear:.4f}\")\n",
    "print(f\"ðŸ“ˆ Linear Regression - RÂ² Score: {r2_linear:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ddde4ad-01c0-42a8-8ef0-077b255d2cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Performance Comparison:\n",
      "Linear Regression - RMSE: 10.4557, RÂ²: 0.9974\n",
      "Random Forest - RMSE: 140.3760, RÂ²: 0.5356\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“Š Model Performance Comparison:\")\n",
    "print(f\"Linear Regression - RMSE: {rmse_linear:.4f}, RÂ²: {r2_linear:.4f}\")\n",
    "print(f\"Random Forest - RMSE: {rmse:.4f}, RÂ²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3973b-aa8e-434d-a358-7e59dc3d6e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
